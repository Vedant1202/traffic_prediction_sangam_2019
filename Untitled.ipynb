{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>Traffic Volume Prediction </h1>\n",
    "    <hr>\n",
    "    <p>\n",
    "        <i>Notebook for the prediction task for IITMAA Sangam 2019 Hackathon</i>\t\n",
    "    </p>\t\n",
    "</center>\n",
    "\n",
    "<p>\n",
    "  <h4>\n",
    "    Requirements to run this notebook:\t    \n",
    "  </h4>\n",
    "  <ul>\n",
    "    <li>Python 3</li>\n",
    "    <li>Pandas</li>\n",
    "    <li>Numpy</li>\n",
    "    <li>Seaborn</li>\n",
    "    <li>Matplotlib</li>\n",
    "    <li>Scikit-Learn</li>\n",
    "  </ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the training dataset and basic data exploration\n",
    "\n",
    "<br>\n",
    "<i>You can load the cleaned and transformed dataset in the latter part as well</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/traffic/DataSets/Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>air_pollution_index</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>visibility_in_miles</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>temperature</th>\n",
       "      <th>rain_p_h</th>\n",
       "      <th>snow_p_h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_type</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-02 09:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>121</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>329</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>288.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>5545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-02 10:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>178</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>289.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>4516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-02 11:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>113</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>329</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>289.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-02 12:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>329</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>290.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>5026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-02 13:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>281</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>329</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>291.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>4918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date_time is_holiday  air_pollution_index  humidity  wind_speed  \\\n",
       "0  2012-10-02 09:00:00       None                  121        89           2   \n",
       "1  2012-10-02 10:00:00       None                  178        67           3   \n",
       "2  2012-10-02 11:00:00       None                  113        66           3   \n",
       "3  2012-10-02 12:00:00       None                   20        66           3   \n",
       "4  2012-10-02 13:00:00       None                  281        65           3   \n",
       "\n",
       "   wind_direction  visibility_in_miles  dew_point  temperature  rain_p_h  \\\n",
       "0             329                    1          1       288.28       0.0   \n",
       "1             330                    1          1       289.36       0.0   \n",
       "2             329                    2          2       289.58       0.0   \n",
       "3             329                    5          5       290.13       0.0   \n",
       "4             329                    7          7       291.14       0.0   \n",
       "\n",
       "   snow_p_h  clouds_all weather_type weather_description  traffic_volume  \n",
       "0       0.0          40       Clouds    scattered clouds            5545  \n",
       "1       0.0          75       Clouds       broken clouds            4516  \n",
       "2       0.0          90       Clouds     overcast clouds            4767  \n",
       "3       0.0          90       Clouds     overcast clouds            5026  \n",
       "4       0.0          75       Clouds       broken clouds            4918  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_time', 'is_holiday', 'air_pollution_index', 'humidity',\n",
       "       'wind_speed', 'wind_direction', 'visibility_in_miles', 'dew_point',\n",
       "       'temperature', 'rain_p_h', 'snow_p_h', 'clouds_all', 'weather_type',\n",
       "       'weather_description', 'traffic_volume'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33750, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make \"weather_type\" and \"is_holiday\" categorical\n",
    "<p>\n",
    "    Here we make the \"weather_type\" and \"is_holiday\" columns categorical. We take in the unique values of each column in a dictionary and replace them with a pre-defined integer. \n",
    "    <br><br>\n",
    "    <i>Note that I have used binary classsification for \"is_holiday\" column ie, if it's a holiday the value is \"1\" or else it's \"0\"</i>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_types = {}\n",
    "\n",
    "for i in range(len(train_data['weather_type'].unique())):\n",
    "    weather_types[train_data['weather_type'].unique()[i]] = int(i)\n",
    "    \n",
    "train_data.replace(weather_types, inplace=True)\n",
    "\n",
    "## Similarly for holiday column\n",
    "is_holiday = {}\n",
    "\n",
    "# value 0 is for no holiday and 1 is for some holiday\n",
    "for i in range(len(train_data['is_holiday'].unique())):\n",
    "    if (train_data['is_holiday'].unique()[i] == 'None'):\n",
    "        is_holiday[train_data['is_holiday'].unique()[i]] = 0\n",
    "    else:\n",
    "        is_holiday[train_data['is_holiday'].unique()[i]] = 1\n",
    "\n",
    "train_data.replace(is_holiday, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>air_pollution_index</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>visibility_in_miles</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>temperature</th>\n",
       "      <th>rain_p_h</th>\n",
       "      <th>snow_p_h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_type</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-02 09:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>329</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>288.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>5545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-02 10:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>289.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>4516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-02 11:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>329</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>289.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-02 12:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>329</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>290.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>5026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-02 13:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>281</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>329</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>291.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>4918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date_time  is_holiday  air_pollution_index  humidity  wind_speed  \\\n",
       "0  2012-10-02 09:00:00           0                  121        89           2   \n",
       "1  2012-10-02 10:00:00           0                  178        67           3   \n",
       "2  2012-10-02 11:00:00           0                  113        66           3   \n",
       "3  2012-10-02 12:00:00           0                   20        66           3   \n",
       "4  2012-10-02 13:00:00           0                  281        65           3   \n",
       "\n",
       "   wind_direction  visibility_in_miles  dew_point  temperature  rain_p_h  \\\n",
       "0             329                    1          1       288.28       0.0   \n",
       "1             330                    1          1       289.36       0.0   \n",
       "2             329                    2          2       289.58       0.0   \n",
       "3             329                    5          5       290.13       0.0   \n",
       "4             329                    7          7       291.14       0.0   \n",
       "\n",
       "   snow_p_h  clouds_all  weather_type weather_description  traffic_volume  \n",
       "0       0.0          40             0    scattered clouds            5545  \n",
       "1       0.0          75             0       broken clouds            4516  \n",
       "2       0.0          90             0     overcast clouds            4767  \n",
       "3       0.0          90             0     overcast clouds            5026  \n",
       "4       0.0          75             0       broken clouds            4918  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>I am dropping \"weather_description\" column here as it's mostly dependant on \"weather_types\" and does not contribute much.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop('weather_description', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Drop duplicates based on \"date_time\" column and reset the index</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop_duplicates(subset='date_time', inplace=True)\n",
    "train_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>air_pollution_index</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>visibility_in_miles</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>temperature</th>\n",
       "      <th>rain_p_h</th>\n",
       "      <th>snow_p_h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_type</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-02 09:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>329</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>288.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>5545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-02 10:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>289.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>4516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-02 11:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>329</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>289.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-02 12:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>329</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>290.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>5026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-02 13:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>281</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>329</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>291.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>4918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date_time  is_holiday  air_pollution_index  humidity  wind_speed  \\\n",
       "0  2012-10-02 09:00:00           0                  121        89           2   \n",
       "1  2012-10-02 10:00:00           0                  178        67           3   \n",
       "2  2012-10-02 11:00:00           0                  113        66           3   \n",
       "3  2012-10-02 12:00:00           0                   20        66           3   \n",
       "4  2012-10-02 13:00:00           0                  281        65           3   \n",
       "\n",
       "   wind_direction  visibility_in_miles  dew_point  temperature  rain_p_h  \\\n",
       "0             329                    1          1       288.28       0.0   \n",
       "1             330                    1          1       289.36       0.0   \n",
       "2             329                    2          2       289.58       0.0   \n",
       "3             329                    5          5       290.13       0.0   \n",
       "4             329                    7          7       291.14       0.0   \n",
       "\n",
       "   snow_p_h  clouds_all  weather_type  traffic_volume  \n",
       "0       0.0          40             0            5545  \n",
       "1       0.0          75             0            4516  \n",
       "2       0.0          90             0            4767  \n",
       "3       0.0          90             0            5026  \n",
       "4       0.0          75             0            4918  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_time', 'is_holiday', 'air_pollution_index', 'humidity',\n",
       "       'wind_speed', 'wind_direction', 'visibility_in_miles', 'dew_point',\n",
       "       'temperature', 'rain_p_h', 'snow_p_h', 'clouds_all', 'weather_type',\n",
       "       'traffic_volume'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AQI Classes for India according to Ministry of Environment, Forest and Climate Change. \n",
    "<hr>\n",
    "#### Here I am making \"air_pollution_index\" column categorical based on this <a href=\"http://pib.nic.in/newsite/PrintRelease.aspx?relid=110654\">info</a>\n",
    "<br>\n",
    "0) Good - (0–50) <br>\n",
    "1) Satisfactory - (51–100) <br>\n",
    "2) Moderately polluted - (101–200) <br>\n",
    "3) Poor - (201–300) <br>\n",
    "4) Very Poor - (301–400) <br>\n",
    "5) Severe - (401-500) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n",
      "21000\n",
      "21100\n",
      "21200\n",
      "21300\n",
      "21400\n",
      "21500\n",
      "21600\n",
      "21700\n",
      "21800\n",
      "21900\n",
      "22000\n",
      "22100\n",
      "22200\n",
      "22300\n",
      "22400\n",
      "22500\n",
      "22600\n",
      "22700\n",
      "22800\n",
      "22900\n",
      "23000\n",
      "23100\n",
      "23200\n",
      "23300\n",
      "23400\n",
      "23500\n",
      "23600\n",
      "23700\n",
      "23800\n",
      "23900\n",
      "24000\n",
      "24100\n",
      "24200\n",
      "24300\n",
      "24400\n",
      "24500\n",
      "24600\n",
      "24700\n",
      "24800\n"
     ]
    }
   ],
   "source": [
    "### Long step. Advised to load pre saved dataset from the latter part\n",
    "for i in range(len(train_data['air_pollution_index'])):\n",
    "    \n",
    "    if (train_data['air_pollution_index'][i] <= 50):\n",
    "        train_data['air_pollution_index'][i] = 0\n",
    "    elif (train_data['air_pollution_index'][i] > 50 and train_data['air_pollution_index'][i] <= 100):\n",
    "        train_data['air_pollution_index'][i] = 1\n",
    "    elif (train_data['air_pollution_index'][i] > 100 and train_data['air_pollution_index'][i] <= 200):\n",
    "        train_data['air_pollution_index'][i] = 2\n",
    "    elif (train_data['air_pollution_index'][i] > 200 and train_data['air_pollution_index'][i] <= 300):\n",
    "        train_data['air_pollution_index'][i] = 3    \n",
    "    else: \n",
    "        train_data['air_pollution_index'][i] = None   \n",
    "        \n",
    "#   Just to make the loop more verbose\n",
    "    if (i % 100 == 0):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I have used the sliding window method for this solution\n",
    "<hr>\n",
    "<p>\n",
    "    Here I use a sliding window which takes in the parameters at (t-1) into account instead of timestamp. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_holiday_lag = pd.DataFrame(data=train_data['is_holiday'].copy().shift(1).tolist(), columns=['is_holiday_lag'])\n",
    "humidity_lag = pd.DataFrame(data=train_data['humidity'].copy().shift(1).tolist(), columns=['humidity_lag'])\n",
    "wind_direction_lag = pd.DataFrame(data=train_data['wind_direction'].copy().shift(1).tolist(), columns=['wind_direction_lag'])\n",
    "dew_point_lag = pd.DataFrame(data=train_data['dew_point'].copy().shift(1).tolist(), columns=['dew_point_lag'])\n",
    "\n",
    "api_lag = pd.DataFrame(data=train_data['air_pollution_index'].copy().shift(1).tolist(), columns=['air_pollution_index_lag'])\n",
    "wind_sp_lag = pd.DataFrame(data=train_data['wind_speed'].copy().shift(1).tolist(), columns=['wind_speed_lag'])\n",
    "vis_lag = pd.DataFrame(data=train_data['visibility_in_miles'].copy().shift(1).tolist(), columns=['visibility_in_miles_lag'])\n",
    "temp_lag = pd.DataFrame(data=train_data['temperature'].copy().shift(1).tolist(), columns=['temperature_lag'])\n",
    "rain_lag = pd.DataFrame(data=train_data['rain_p_h'].copy().shift(1).tolist(), columns=['rain_p_h_lag'])\n",
    "snow_lag = pd.DataFrame(data=train_data['snow_p_h'].copy().shift(1).tolist(), columns=['snow_p_h_lag'])\n",
    "clouds_lag = pd.DataFrame(data=train_data['clouds_all'].copy().shift(1).tolist(), columns=['clouds_all_lag'])\n",
    "weather_lag = pd.DataFrame(data=train_data['weather_type'].copy().shift(1).tolist(), columns=['weather_type_lag'])\n",
    "traffic_lag = pd.DataFrame(data=train_data['traffic_volume'].copy().shift(1).tolist(), columns=['traffic_volume_lag'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dates = train_data.copy()['date_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop the date_time column\n",
    "train_data_lag = pd.concat([train_data.copy().drop(['date_time'], axis=1), is_holiday_lag, humidity_lag, wind_direction_lag, \n",
    "                            dew_point_lag, api_lag, wind_sp_lag, vis_lag, temp_lag, rain_lag, snow_lag, clouds_lag, weather_lag,\n",
    "                            traffic_lag], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_lag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_lag.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_lag.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we have shifted the lag columns down, there would be an empty row at the top. So we substitute it with appropriate values.\n",
    "<i>For the latter two columns we use the \"mode\" and for former we use the \"mean\"</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['air_pollution_index_lag', 'wind_speed_lag', 'visibility_in_miles_lag', 'temperature_lag', 'rain_p_h_lag', \n",
    "        'snow_p_h_lag', 'humidity_lag', 'wind_direction_lag', 'dew_point_lag', 'clouds_all_lag', 'traffic_volume_lag']\n",
    "\n",
    "for i in cols:\n",
    "    train_data_lag[i].iloc[0] = train_data_lag.describe()[i].iloc[1]\n",
    "#     train_data_lag.iloc[-1] = train_data_lag.describe()[i].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['is_holiday_lag', 'weather_type_lag']:\n",
    "    train_data_lag[i].iloc[0] = train_data_lag.mode()[i].iloc[0]\n",
    "#     train_data_lag[i].iloc[-1] = train_data_lag.mode()[i].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Get the correlation between original features and laggin features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(train_data_lag.corr(), cmap='viridis',  linewidths=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Good correlation:</h1> \n",
    "\n",
    "<h3>\n",
    "humidity, windspeed, winddirection, visibility, dew point, temperature, snow, clouds, traffic\n",
    "</h3>\n",
    "<br>\n",
    "<br>\n",
    "<i>We drop the remaining features</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_lag.drop(['rain_p_h', 'rain_p_h_lag', 'weather_type', 'weather_type_lag'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_lag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_lag.to_csv('./analysis/train_data_lag.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import readymade training dataset here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_lag = pd.read_csv('./analysis/train_data_lag.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the features except the categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_lag.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_lag_std = pd.DataFrame(scaler.fit_transform(train_data_lag.drop(['is_holiday', 'is_holiday_lag',\n",
    "                                                                            'air_pollution_index', 'air_pollution_index_lag'],\n",
    "                                                                            axis=1)),\n",
    "                                  columns=train_data_lag.columns.delete([0, 1, 15, 11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_lag_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_lag_std = pd.concat([train_data_lag['is_holiday'], train_data_lag['is_holiday_lag'],\n",
    "                                train_data_lag['air_pollution_index'], train_data_lag['air_pollution_index_lag'], \n",
    "                                train_data_lag_std], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_lag_std.drop(['traffic_volume', 'traffic_volume_lag'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_lag_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the Y values of traffic_volume\n",
    "train_traffic = train_data.copy()['traffic_volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data\n",
    "\n",
    "### We do the same steps on the test data as well.\n",
    "#### You can import the pre-saved test dataset from the latter part as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./data/traffic/DataSets/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_types = train_data['weather_type'].unique()\n",
    "weather_types = {}\n",
    "\n",
    "for i in range(len(test_data['weather_type'].unique())):\n",
    "    weather_types[test_data['weather_type'].unique()[i]] = int(i)\n",
    "\n",
    "test_data.replace(weather_types, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_holiday = {}\n",
    "\n",
    "# value 0 is for no holiday and 1 is for some holiday\n",
    "for i in range(len(test_data['is_holiday'].unique())):\n",
    "    if (test_data['is_holiday'].unique()[i] == 'None'):\n",
    "        is_holiday[test_data['is_holiday'].unique()[i]] = 0\n",
    "    else:\n",
    "        is_holiday[test_data['is_holiday'].unique()[i]] = 1\n",
    "\n",
    "test_data.replace(is_holiday, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.drop('weather_description', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.drop(['rain_p_h', 'weather_type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Long step. Advised to load pre saved dataset from the latter part\n",
    "for i in range(len(test_data['air_pollution_index'])):\n",
    "    \n",
    "    if (test_data['air_pollution_index'][i] <= 50):\n",
    "        test_data['air_pollution_index'][i] = 0\n",
    "    elif (test_data['air_pollution_index'][i] > 50 and test_data['air_pollution_index'][i] <= 100):\n",
    "        test_data['air_pollution_index'][i] = 1\n",
    "    elif (test_data['air_pollution_index'][i] > 100 and test_data['air_pollution_index'][i] <= 200):\n",
    "        test_data['air_pollution_index'][i] = 2\n",
    "    elif (test_data['air_pollution_index'][i] > 200 and test_data['air_pollution_index'][i] <= 300):\n",
    "        test_data['air_pollution_index'][i] = 3    \n",
    "    else: \n",
    "        test_data['air_pollution_index'][i] = None   \n",
    "        \n",
    "#   Just to make the loop more verbose\n",
    "    if (i % 100 == 0):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_holiday_lag_test = pd.DataFrame(data=test_data['is_holiday'].copy().shift(1).tolist(), columns=['is_holiday_lag'])\n",
    "humidity_lag_test = pd.DataFrame(data=test_data['humidity'].copy().shift(1).tolist(), columns=['humidity_lag'])\n",
    "wind_direction_lag_test = pd.DataFrame(data=test_data['wind_direction'].copy().shift(1).tolist(), columns=['wind_direction_lag'])\n",
    "dew_point_lag_test = pd.DataFrame(data=test_data['dew_point'].copy().shift(1).tolist(), columns=['dew_point_lag'])\n",
    "\n",
    "api_lag_test = pd.DataFrame(data=test_data['air_pollution_index'].copy().shift(1).tolist(), columns=['air_pollution_index_lag'])\n",
    "wind_sp_lag_test = pd.DataFrame(data=test_data['wind_speed'].copy().shift(1).tolist(), columns=['wind_speed_lag'])\n",
    "vis_lag_test = pd.DataFrame(data=test_data['visibility_in_miles'].copy().shift(1).tolist(), columns=['visibility_in_miles_lag'])\n",
    "temp_lag_test = pd.DataFrame(data=test_data['temperature'].copy().shift(1).tolist(), columns=['temperature_lag'])\n",
    "snow_lag_test = pd.DataFrame(data=test_data['snow_p_h'].copy().shift(1).tolist(), columns=['snow_p_h_lag'])\n",
    "clouds_lag_test = pd.DataFrame(data=test_data['clouds_all'].copy().shift(1).tolist(), columns=['clouds_all_lag'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_lag = pd.concat([test_data.copy().drop(['date_time'], axis=1), is_holiday_lag_test, humidity_lag_test,\n",
    "                            wind_direction_lag_test, dew_point_lag_test, api_lag_test, wind_sp_lag_test, vis_lag_test,\n",
    "                            temp_lag_test, snow_lag_test, clouds_lag_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['air_pollution_index_lag', 'wind_speed_lag', 'visibility_in_miles_lag', 'temperature_lag', \n",
    "        'snow_p_h_lag', 'humidity_lag', 'wind_direction_lag', 'dew_point_lag', 'clouds_all_lag']\n",
    "\n",
    "for i in cols:\n",
    "    test_data_lag[i].iloc[0] = test_data_lag.describe()[i].iloc[1]\n",
    "#     test_data_lag[i].iloc[-1] = test_data_lag.describe()[i].iloc[1]\n",
    "    \n",
    "\n",
    "test_data_lag['is_holiday_lag'].iloc[0] = test_data_lag.mode()[i].iloc[0]\n",
    "# test_data_lag['is_holiday_lag'].iloc[-1] = test_data_lag.mode()[i].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_lag.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_lag.to_csv('./analysis/test_data_lag.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_lag = pd.read_csv('./analysis/test_data_lag.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_lag_std = pd.DataFrame(scaler.fit_transform(test_data_lag.drop(['is_holiday', 'is_holiday_lag',\n",
    "                                                                         'air_pollution_index', 'air_pollution_index_lag'],\n",
    "                                                                         axis=1)),\n",
    "                                  columns=test_data_lag.columns.delete([0, 1, 14, 11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_lag_std = pd.concat([test_data_lag['is_holiday'], test_data_lag['is_holiday_lag'], \n",
    "                               test_data_lag['air_pollution_index'], test_data_lag['air_pollution_index_lag'], \n",
    "                               test_data_lag_std], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_lag_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dates = test_data.copy()['date_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise the Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=600, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.fit(train_data_lag.drop(['traffic_volume', 'traffic_volume_lag'], axis=1), train_traffic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the predictions and make a dataframe containing the test dates and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df_rf = pd.concat([test_dates, pd.DataFrame(rf_model.predict(test_data_lag), columns=['traffic_volume'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_df_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df_rf.to_csv('./predictions/preds_v12_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
